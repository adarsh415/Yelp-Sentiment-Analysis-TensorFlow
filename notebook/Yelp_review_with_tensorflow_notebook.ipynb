{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(filename):\n",
    "    \n",
    "    labels=[]\n",
    "    feature=[]\n",
    "    with open(filename,'r') as f:\n",
    "        line = csv.reader(f)\n",
    "        next(line,None)\n",
    "        for row in line:\n",
    "            feature.append([ np.int32(dictionary[x]) if x in dictionary else 0 for x in row[1].split()])\n",
    "            labels.append(np.int32(row[0]))\n",
    "    return feature, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(fileName):\n",
    "    text=[]\n",
    "    with open(fileName,'r') as f:\n",
    "        line = csv.reader(f)\n",
    "        next(line,None)\n",
    "        for row in line:\n",
    "            text.extend(row[1].replace('\\n','<eos>').split())\n",
    "    count=[['UNK',1]]\n",
    "    count.extend(Counter(text).most_common())\n",
    "    dictionary = dict()\n",
    "    for word ,_ in count:\n",
    "        dictionary[word]=len(dictionary)\n",
    "    reverse_dictionary=dict(zip(dictionary.values(),dictionary.keys()))\n",
    "    del text\n",
    "    return dictionary,reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_row(arr,test=False):\n",
    "    if test:\n",
    "        max_len=424\n",
    "    else:\n",
    "        max_len=max(len(row) for row in arr)\n",
    "    arr_padded = np.array([row + [0]*(max_len - len(row)) for row in arr])\n",
    "    return arr_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary,reverse_dictionary=build_vocab('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15694"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15694"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature,labels=create_data('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(arr,):\n",
    "    arr=arr\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i]==5:\n",
    "            arr[i]=1\n",
    "            \n",
    "        else:\n",
    "            arr[i]=0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=encode_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature=np.array(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_padd = padd_row(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feature_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data = tf.convert_to_tensor(feature_padd,dtype=tf.int32,name='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feature_padd)\n",
    "#x_data[:100,0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(feature,label,batch_size,test=False):\n",
    "    #assert feature.shape[0]%batch_size==0,\"Use batch size in multiple of 10\"\n",
    "    feature_padd = padd_row(feature,test)\n",
    "    #x_data = tf.convert_to_tensor(feature_padd,dtype=tf.int32,name='feature')\n",
    "    #data_size = tf.size(x_data)\n",
    "    no_batch = len(feature_padd)//batch_size\n",
    "    #data = tf.reshape(x_data[:no_batch*batch_size],[batch_size,no_batch]) # or we can user [batch_size,-1]\n",
    "    #labels = tf.convert_to_tensor(np.array(label),dtype=tf.int32,name='label')\n",
    "    label=np.array(label)\n",
    "    x_=feature_padd[:no_batch*batch_size]\n",
    "    y_=label[:no_batch*batch_size]\n",
    "    \n",
    "    for n in range(0, len(x_), batch_size):\n",
    "        #x = data[:,n:n+seq_n]\n",
    "        x = x_[n:n+batch_size]\n",
    "        y = y_[n:n+batch_size]\n",
    "    \n",
    "        yield x ,y.reshape((batch_size,1))  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  20  322   85 ...    0    0    0]\n",
      " [   1  517   42 ...    0    0    0]\n",
      " [   1  330 8077 ...    0    0    0]\n",
      " ...\n",
      " [   4   90 4499 ...    0    0    0]\n",
      " [ 148  959   22 ...    0    0    0]\n",
      " [ 101 8227  960 ...    0    0    0]]\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "batch = create_batch(feature,labels,50,424)\n",
    "x,y=next(batch)\n",
    "print (x)\n",
    "print (y.shape)\n",
    "#for e in range(20):\n",
    "    #for x,y in create_batch(feature,labels,100):\n",
    "        #print (x)\n",
    "        #print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell(lstm_size,keep_prob):\n",
    "    with tf.variable_scope(\"cells\"):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(lstm_size,reuse=tf.get_variable_scope().reuse)\n",
    "        drop = tf.nn.rnn_cell.DropoutWrapper(cell,output_keep_prob=keep_prob)\n",
    "    return drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input(batch_size,num_setps,num_classes):\n",
    "    inputs = tf.placeholder(tf.int32,[None,num_setps],name='input')\n",
    "    targets = tf.placeholder(tf.float32,[None,None],name='targets')\n",
    "    keep_proba = tf.placeholder(tf.float32,name='keep_proba')\n",
    "    \n",
    "    return inputs,targets,keep_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size,num_layers,batch_size,keep_proba):\n",
    "    with tf.variable_scope(\"LSTM_Network\"):\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([create_cell(lstm_size,keep_proba) for _ in range(num_layers)])\n",
    "        initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "    \n",
    "    return cell,initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpNetwork(object):\n",
    "    def __init__(self,\n",
    "                 lstm_size,\n",
    "                 batch_size,\n",
    "                 num_layers,\n",
    "                 vocab,\n",
    "                 numClasses=2,\n",
    "                 num_steps=424,\n",
    "                 learning_rate=0.001,\n",
    "                 grad_clip=0.5,\n",
    "                 embedding_size=300):\n",
    "        \n",
    "        self.lstm_size=lstm_size\n",
    "        self.batch_size=batch_size\n",
    "        self.num_layers=num_layers\n",
    "        self.vocab_size=len(vocab)\n",
    "        self.numClasses=numClasses\n",
    "        self.grad_clip=grad_clip\n",
    "        self.inputs,self.target,self.keep_proba=build_input(self.batch_size,num_steps,numClasses)\n",
    "        self.learning_rate=learning_rate\n",
    "        self.embedding= self.embedding_matrix(self.inputs,embedding_size,self.vocab_size)\n",
    "        self.logits,self.out=self.build_output()\n",
    "        self.loss=self.build_loss()\n",
    "        self.optimizer=self.build_optimizer()\n",
    "        self.accuracy =self.accuracy()\n",
    "        \n",
    "    \n",
    "    def embedding_matrix(self,x,embedding_size,vocab_size):\n",
    "        with tf.variable_scope('embedding'):\n",
    "            embedd = tf.Variable(tf.random_uniform([vocab_size,embedding_size],-0.1,0.1))\n",
    "            embedding=tf.nn.embedding_lookup(embedd,x)\n",
    "        return embedding\n",
    "    \n",
    "    def build_output(self):\n",
    "        \n",
    "        with tf.variable_scope(\"dynamic_rnn\",reuse=tf.AUTO_REUSE):\n",
    "            cell,self.initial_state = build_lstm(self.lstm_size,self.num_layers,self.batch_size,self.keep_proba)\n",
    "            output,state = tf.nn.dynamic_rnn(cell, self.embedding,initial_state=self.initial_state)\n",
    "            self.final_state = state\n",
    "        #output_flat = tf.reshape(output,[:,-1])\n",
    "        \n",
    "        with tf.variable_scope('softmax',reuse=tf.AUTO_REUSE):\n",
    "            softmax_w = tf.Variable(tf.truncated_normal([self.lstm_size,self.numClasses],stddev=0.1))\n",
    "            softmax_b = tf.Variable(tf.truncated_normal([self.numClasses],stddev=0.1))\n",
    "        \n",
    "        logits = tf.nn.xw_plus_b(output[:,-1],softmax_w,softmax_b)\n",
    "        #logits = tf.sigmoid(logits,name='sigmoid')\n",
    "        out = tf.nn.sigmoid(logits,name='predictions')\n",
    "        #out = tf.argmax(out,axis=1)\n",
    "        return logits,out\n",
    "    \n",
    "    def build_loss(self):\n",
    "        \n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            \n",
    "            #y_one_hot = tf.one_hot(self.target,self.numClasses)\n",
    "            #y_reshaped = tf.reshape(y_one_hot,(self.logits.get_shape()))\n",
    "        \n",
    "            loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.target,logits=self.logits)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def build_optimizer(self):\n",
    "        \n",
    "        with tf.variable_scope(\"optimizer\"):\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads,_ = tf.clip_by_global_norm(tf.gradients(self.loss,tvars),self.grad_clip)\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "            optimizer = train_op.apply_gradients(zip(grads,tvars))\n",
    "        return optimizer\n",
    "   \n",
    "    def accuracy(self):\n",
    "        with tf.variable_scope(\"accuracy\"):\n",
    "            #y_one_hot_test = tf.one_hot(self.target,self.numClasses)\n",
    "            correct_predictions = tf.equal(tf.cast(tf.argmax(self.out,1),tf.float32),self.target)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_predictions,'float'))\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100         # Sequences per batch\n",
    "#num_steps = 100          # Number of sequence steps per batch\n",
    "lstm_size = 512         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "#learning_rate = 0.001    # Learning rate\n",
    "keep_prob = 0.5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "save_every_n = 100\n",
    "\n",
    "model = YelpNetwork(lstm_size,batch_size,num_layers,dictionary)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for e in range (epoch):\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0.0\n",
    "        for x,y in create_batch(feature,labels,batch_size):\n",
    "        #while True:\n",
    "            #x,y=next(create_batches(encoded, batch_size, num_steps))\n",
    "            counter +=1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.target: y,\n",
    "                    model.keep_proba: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            \n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer\n",
    "                                                 ], \n",
    "                                                 feed_dict=feed)\n",
    "            loss +=batch_loss\n",
    "            end = time.time()\n",
    "            print('Epoch: {}/{}... '.format(e+1, epoch),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  #'Training state: {:.4f}... '.format(new_state),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    #print ('Out : ',out) \n",
    "    #print ('Logits : ',logits)\n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature,test_labels=create_data('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=encode_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accu=[]\n",
    "out_put=[]\n",
    "model = YelpNetwork(lstm_size,batch_size,num_layers,dictionary)\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('checkpoints'))\n",
    "    #saver.restore(sess,'checkpoints\\\\i10_l512.ckpt')\n",
    "    test_state=sess.run(model.initial_state)\n",
    "    for x,y in create_batch(test_feature,test_labels,batch_size,test=True):\n",
    "        feed = {model.inputs: x,\n",
    "                model.target: y,\n",
    "                model.keep_proba: 1,\n",
    "                model.initial_state: test_state}\n",
    "        accu,test_state,out=sess.run([model.accuracy,model.final_state,model.out],feed_dict=feed)\n",
    "        test_accu.append(accu)\n",
    "        out_put.extend(out)\n",
    "        \n",
    "    print('Test Accuracy: ',np.mean(test_accu))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the review: I usually write horrified experience I Went late night bite drink fairly busy seat As I frequent The Moon I happy see bar busy The bartender quickly came noticably could even tell flavors vodka We ordered watched broke glass knocked glassware broke beer As looked around guests look horror We decided order spilled drink us something completely could barely even talk We saw management watch behavior preceded grab dirty glassware refill I appauled left befpre finishing drinks sure visible paying customers visible Being beyond embarassed I would doubt I come sad would frequent Moon times\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = input('enter the review: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I usually write horrified experience I Went late night bite drink fairly busy seat As I frequent The Moon I happy see bar busy The bartender quickly came noticably could even tell flavors vodka We ordered watched broke glass knocked glassware broke beer As looked around guests look horror We decided order spilled drink us something completely could barely even talk We saw management watch behavior preceded grab dirty glassware refill I appauled left befpre finishing drinks sure visible paying customers visible Being beyond embarassed I would doubt I come sad would frequent Moon times'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(review):\n",
    "    model= YelpNetwork(lstm_size,1,num_layers,dictionary)\n",
    "    saver = tf.train.Saver()\n",
    "    inputs = [ np.int32(dictionary[x]) if x in dictionary else 0 for x in review.split()]\n",
    "    padd_input = inputs+[0]*(424 - len(inputs))\n",
    "    padd_input = np.reshape(np.array(padd_input),(1,424))\n",
    "    #padd_input = np.array(padd_input)\n",
    "    print(padd_input)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    \n",
    "    init_state = sess.run(model.initial_state)\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('checkpoints'))\n",
    "    feed = {model.inputs: padd_input,\n",
    "            model.keep_proba: 1,\n",
    "            model.initial_state: init_state}\n",
    "    out,_ = sess.run([model.out,model.final_state],feed_dict=feed)\n",
    "    return np.argmax(np.array(out)),np.argmax(out),out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "[[    1   236   888     0    87     1   698   651   101   548   160  1588\n",
      "    433   813   148     1  1070     2  2213     1    84    55    95   433\n",
      "      2   824   558    54     0    31    24   212   353  5258    10    38\n",
      "   2041  1522   403 15621     0  1522   225   148   218    76   995   133\n",
      "   8874    10   166    52  3286   160    30    88   503    31   900    24\n",
      "    599    10   323  1184   624  5311     0   669  1386     0  2082     1\n",
      "      0   207     0  3658   246    79     0   693   449     0  1072   862\n",
      "  14314     1    14  1454     1    56   934    14  1070  2213    97     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\i200_l512.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0, array([[0.8350291, 0.8289568]], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rating(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
